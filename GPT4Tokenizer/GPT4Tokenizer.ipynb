{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9852225",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 50 (438108441.py, line 53)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 53\u001b[0;36m\u001b[0m\n\u001b[0;31m    def encode(self, text):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 50\n"
     ]
    }
   ],
   "source": [
    "class BassicTokenizer:\n",
    "    def __init__(self):\n",
    "        self.vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "        self.merges = {}\n",
    "        pass\n",
    "\n",
    "    def getTokens(self, text):\n",
    "        tokens = text.encode(\"utf-8\")\n",
    "        return list(map(int, tokens))\n",
    "\n",
    "    def stats(self, tokens):\n",
    "        stats = {}\n",
    "        for pair in zip(tokens, tokens[1:]):\n",
    "            if pair not in stats:\n",
    "                stats[pair] = 0\n",
    "            stats[pair] += 1\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "\n",
    "    def merge(self, encodings, pair, idx):\n",
    "        newIds = []\n",
    "        i = 0\n",
    "        while i < len(encodings):\n",
    "            if i + 1 < len(encodings) and pair[0] == encodings[i] and pair[1] == encodings[i+1]:\n",
    "                newIds.append(idx)\n",
    "                i += 2\n",
    "            else:\n",
    "                newIds.append(encodings[i])\n",
    "                i += 1\n",
    "            \n",
    "        return newIds\n",
    "\n",
    "\n",
    "    def train(self, text, vocabSize, verbose=False):\n",
    "        assert vocabSize\n",
    "        numMerges = vocabSize - 256\n",
    "        tokens = self.getTokens(text)\n",
    "        ids = list(tokens)\n",
    "\n",
    "        \n",
    "        for i in range(numMerges):\n",
    "            stas = self.stats(ids)\n",
    "            topPair = max(stas, key=stas.get)\n",
    "            idx = 256+i\n",
    "            print(f\"merge {topPair} -> {idx}\")\n",
    "            ids = self.merge(ids, topPair, idx)\n",
    "            self.merges[topPair] = idx\n",
    "        \n",
    "        for (p0, p1), idx in self.merges.items():\n",
    "            self.vocab[idx] = self.vocab[p0] + self.vocab[p1]            \n",
    "\n",
    "    def encode(self, text):\n",
    "        tokens = self.getTokens(text)\n",
    "        while len(tokens) > 1:\n",
    "            stas = self.stats(tokens)\n",
    "            pair = min(stas, key= lambda p: self.merges.get(p, float('inf')))\n",
    "            if pair not in self.merges:\n",
    "                break\n",
    "                \n",
    "            idx = self.merges[pair]\n",
    "            tokens = self.merge(tokens, pair, idx)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bde79aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
